{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 는 구글에서 만든 머신러닝 라이브러리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ol>tf.keras.layers</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서플로우 버전확인\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 설정! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", \n",
    "len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()\n",
    "\n",
    "\n",
    "(ds_train, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train', 'test'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    ")\n",
    "\n",
    "def normalize_img(image, label):\n",
    "  \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "  return tf.cast(image, tf.float32) / 255., label\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_train = ds_train.cache()\n",
    "ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)\n",
    "ds_train = ds_train.batch(batch_size)\n",
    "ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "ds_test = ds_test.batch(batch_size)\n",
    "ds_test = ds_test.cache()\n",
    "ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.Conv2D(64, kernel_size=(3, 3),\n",
    "                 activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#   tf.keras.layers.Dropout(0.25),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "#   tf.keras.layers.Dropout(0.5),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=12,\n",
    "    validation_data=ds_test,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 13:55:10.337401: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-02 13:55:10.337526: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = (20,1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "output = tf.keras.layers.Dense(units=10,activation=tf.nn.sigmoid)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (20,1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "hidden = tf.keras.layers.Dense(units=10,activation=tf.nn.sigmoid)(inputs)\n",
    "output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신경망 모델을 만들 때 생기는 문제점 중 대표적인 문제점으로 과적합(Overfitting)이 있다\n",
    "#과적합 문제는 정규화(Regularization)방법을 사용해서 해결하는데, 가장 대표적인 방법이 드롭아웃(Dropout)이다.\n",
    "\n",
    "INPUT_SIZE = (20,1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "#Dropout의 rate=0.5는 전체 입력값중에 50%를 0으로 만든다는 뜻\n",
    "dropout = tf.keras.layers.Dropout(rate=0.5)(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout은 tf.keras.layers뿐만 아니라 tf.nn모델에도 있는데 \n",
    "# 두 모듈의 차이점은 tf.keras.layers.Dropout의 경우 확률을 0.2라 했을때 20%를 0으로 만들지만\n",
    "# tf.nn.dropout은 0.2라 했을때 80%를 0으로 만든다.\n",
    "\n",
    "INPUT_SIZE = (20 , 1)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "hidden = tf.keras.layers.Dense(units=10,activation=tf.nn.sigmoid)(dropout)\n",
    "output = tf.keras.layers.Dense(units=2, activation=tf.nn.sigmoid)(hidden)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 연산중 Conv1D를 알아보자\n",
    "# 책의 24page 참조\n",
    "# Conv1D의 기본사용법\n",
    "\n",
    "INPUT_SIZE = (1,28,28)\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SIZE)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters=10,#필터의 개수로, 정수형으로 지정한다. 출력의 차원수를 나타낸다.\n",
    "    kernel_size=3, #필터의 크기로서, 정수 혹은 정수의 리스트, 튜플 형태로 지정한다. 합성곱이 적용되는 윈도의 길이를 나타낸다.\n",
    "    padding='same', #패딩 방법을 지정한다. 'VALID'혹은 'SAME'으로 지정가능\n",
    "    activation=tf.nn.relu #활성화 함수\n",
    ")(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값의 드롭아웃을 적용한 합성곱 신경망도 Dropout과 Conv1D를 사용해서 구현할 수 있다.\n",
    "\n",
    "INPUT_SIZE = (1,28,28)\n",
    "\n",
    "inputs=tf.keras.Input(shape= INPUT_SIZE)\n",
    "dropout = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters=10,\n",
    "    kernel_size = 3,\n",
    "    padding='same',\n",
    "    activation = tf.nn.relu)(dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf.keras.layers.MaxPool1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"max_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, 28, 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 13\u001b[0m\n\u001b[1;32m      7\u001b[0m dropouts \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(rate\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m)(inputs)\n\u001b[1;32m      8\u001b[0m conv \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mConv1D(\n\u001b[1;32m      9\u001b[0m     filters\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,\n\u001b[1;32m     10\u001b[0m     kernel_size\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,\n\u001b[1;32m     11\u001b[0m     padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m     activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu)(dropouts)\n\u001b[0;32m---> 13\u001b[0m max_pool \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mMaxPool1D(pool_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msame\u001b[39;49m\u001b[39m'\u001b[39;49m)(conv)\n\u001b[1;32m     14\u001b[0m flatten \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mFlatten()(max_pool) \u001b[39m# Flatten 은 맥스 풀링 결괏값을 완전 연결 계층으로 연결하기 위해서는 행렬이었던 것을 벡터로 만들어준다.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m hidden \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(units\u001b[39m=\u001b[39m\u001b[39m50\u001b[39m, activation\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mrelu)(flatten)\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniforge3/envs/ml/lib/python3.8/site-packages/keras/engine/input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    230\u001b[0m     ndim \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39mrank\n\u001b[1;32m    231\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39m!=\u001b[39m spec\u001b[39m.\u001b[39mndim:\n\u001b[0;32m--> 232\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    233\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mndim\u001b[39m}\u001b[39;00m\u001b[39m, found ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mmax_ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"max_pooling1d\" is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (None, 1, 28, 10)"
     ]
    }
   ],
   "source": [
    "# tf.keras.layers.MaxPool1D 는 합성곱 신경망과 함께 쓰이는 기법 중 하나\n",
    "# 피처 맵크기를 줄이거나 주요한 특징을 뽑아내기 위해 합성곱 이후에 적용되는 기법\n",
    "\n",
    "INPUT_SIZE = (1,28,28)\n",
    "\n",
    "inputs = tf.keras.Input(shape=INPUT_SIZE)\n",
    "dropouts = tf.keras.layers.Dropout(rate=0.2)(inputs)\n",
    "conv = tf.keras.layers.Conv1D(\n",
    "    filters=10,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu)(dropouts)\n",
    "max_pool = tf.keras.layers.MaxPool1D(pool_size=3, padding='same')(conv)\n",
    "flatten = tf.keras.layers.Flatten()(max_pool) # Flatten 은 맥스 풀링 결괏값을 완전 연결 계층으로 연결하기 위해서는 행렬이었던 것을 벡터로 만들어준다.\n",
    "hidden = tf.keras.layers.Dense(units=50, activation=tf.nn.relu)(flatten)\n",
    "output = tf.keras.layers.Dense(units=10, activation=tf.nn.softmax)(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li> Sequential API</li>\n",
    "<li>Functional API</li>\n",
    "<li>Functional / Sequential API</li><ol>+ Custom Layers</ol>    \n",
    "<li>Sequential API(Custom Model)</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential API\n",
    "\n",
    "<li> 케라스를 활용해 모델을 구축하는데 가장 간단한 API</li>\n",
    "<li> 하나의 플로만 계산할 수 있는 Sequentioal은 두 개의 값을 합칠 수가 없어서 여러 제약이 존재</li>\n",
    "<ol>\n",
    "    <li>다중 입력값 모델(Multi-input models)</li>\n",
    "    <li>다중 출력값 모델(Multi-output models)</li>\n",
    "    <li>공유 층을 활용하는 모델(Models with shared layers)</li>\n",
    "    <li>데이터 흐름이 순차적이지 않은 모델(Models with non-sequential data flows)</li>\n",
    "</ol>\n",
    "<li>에서는 여러 제약이 존재</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:12:35.553467: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-02 14:12:35.553596: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dense(units=64, activation='relu'))\n",
    "model.add(layers.Dense(units=10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API\n",
    "<ol>\n",
    "    <li>다중 입력값 모델(Multi-input models)</li>\n",
    "    <li>다중 출력값 모델(Multi-output models)</li>\n",
    "    <li>공유 층을 활용하는 모델(Models with shared layers)</li>\n",
    "    <li>데이터 흐름이 순차적이지 않은 모델(Models with non-sequential data flows)</li>\n",
    "</ol>\n",
    " \n",
    "<li></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(32,))\n",
    "x = layers.Dense(64, activation='relu')(inputs)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Layer\n",
    "\n",
    "<li>Sequential API 와 Functional API 를 사용하기 위해 케라스의 layers 패키지에 정의된 레이어를 사용해 구현했다</li>\n",
    "<li>새로운 연산을 하는 레이어 or 편의를 위해 여러 레이어를 하나로 묶은 레이어를 구현해야하는 경우가 있다</li>\n",
    "<li>이때 사용자 정의 층(custom layer)을 만들어 사용하면 된다.</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, hidden_dimension, hidden_dimension2, output_dimension):\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.hidden_dimension2 = hidden_dimension2\n",
    "        self.output_dimension = output_dimension\n",
    "        super(CustomLayer, self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_layer1 = layers.Dense(self.hidden_dimension, activation = 'relu')\n",
    "        self.dense_layer2 = layers.Dense(self.hidden_dimension2, activation = 'relu')\n",
    "        self.dense_layer3 = layers.Dense(self.output_dimension, activation = 'softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hidden_output = self.dense_layer1(inputs)\n",
    "        hidden_output = self.dense_layer2(hidden_output)\n",
    "        return self.dense_layer2(hidden_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(CustomLayer(64,64,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subclassing (Custom Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,hidden_dimension, hidden_dimension2, output_dimension):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.dense_layer1 = layers.Dense(hidden_dimension, activation='relu')\n",
    "        self.dense_layer2 = layers.Dense(hidden_dimension2, activation='relu')\n",
    "        self.output_layer = layers.Dense(output_dimension, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense_layer1(inputs)\n",
    "        x = self.dense_layer2(x)\n",
    "        \n",
    "        return self.dense_layer3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이제 본격적으로 모델을 구현해 보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 1, 5, 6], [7, 1, 8, 9], [10, 2, 3, 11], [12, 2, 3, 13], [14, 1, 15, 16], [17, 18, 19, 20]]\n",
      "[[ 4  1  5  6]\n",
      " [ 7  1  8  9]\n",
      " [10  2  3 11]\n",
      " [12  2  3 13]\n",
      " [14  1 15 16]\n",
      " [17 18 19 20]]\n",
      "{'오늘': 1, '좋은': 2, '일이': 3, '너': 4, '이뻐': 5, '보인다': 6, '나는': 7, '기분이': 8, '더러워': 9, '끝내주는데': 10, '있나봐': 11, '나': 12, '생겼어': 13, '아': 14, '진짜': 15, '짜증나': 16, '환상적인데': 17, '정말': 18, '좋은거': 19, '같아': 20}\n"
     ]
    }
   ],
   "source": [
    "#텍스트 데이터를 토큰화하기!\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "samples = ['너 오늘 이뻐 보인다',\n",
    "          '나는 오늘 기분이 더러워',\n",
    "          '끝내주는데, 좋은 일이 있나봐',\n",
    "          '나 좋은 일이 생겼어',\n",
    "          '아 오늘 진짜 짜증나',\n",
    "          '환상적인데, 정말 좋은거 같아']\n",
    "\n",
    "labels = [[1],[0],[1],[1],[0],[1]]\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "print(sequences)\n",
    "\n",
    "input_sequences = np.array(sequences)\n",
    "print(input_sequences)\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가로 모델 구축 및 모델 학습에 필요한 변수 정의\n",
    "\n",
    "batch_size = 2\n",
    "num_epochs = 100\n",
    "vocab_size = len(word_index) + 1\n",
    "emb_size = 128\n",
    "hidden_dimension = 256\n",
    "output_dimension = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Embedding(vocab_size, emb_size, input_length=4))\n",
    "model.add(layers.Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "model.add(layers.Dense(hidden_dimension, activation='relu'))\n",
    "model.add(layers.Dense(output_dimension, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 4, 128)            2688      \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:12:44.925960: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-02 14:12:45.291821: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 18ms/step - loss: 0.6950 - accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6759 - accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6611 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.6458 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6272 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6091 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5851 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5570 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5255 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4873 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4473 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3999 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3523 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3027 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2540 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2082 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1686 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1321 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1062 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0804 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0645 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0499 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0378 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0309 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0239 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0135 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0089 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.9076e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.7002e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.4665e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 9.2244e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.9847e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.7772e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.5898e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.3934e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.2018e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.0309e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.8130e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.6616e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.5025e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.3170e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 7.1835e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.0220e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 6.8844e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 6.7411e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.6020e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.4749e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.3362e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.2241e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.0788e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17e01f730>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape = (4, ))\n",
    "embed_output = layers.Embedding(vocab_size, emb_size)(inputs)\n",
    "pooled_output = tf.reduce_mean(embed_output, axis=1)\n",
    "hidden_layer = layers.Dense(hidden_dimension, activation='relu')(pooled_output)\n",
    "outputs = layers.Dense(output_dimension, activation='sigmoid')(hidden_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 4, 128)            2688      \n",
      "                                                                 \n",
      " tf.math.reduce_mean (TFOpLa  (None, 128)              0         \n",
      " mbda)                                                           \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,969\n",
      "Trainable params: 35,969\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6932 - accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:12:52.144715: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6729 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6537 - accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6351 - accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6137 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5901 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5607 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5279 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4898 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4478 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4021 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.3530 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3027 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.2550 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2096 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1716 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1357 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0848 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0666 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0225 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0129 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0099 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.8921e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.6580e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.3668e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 9.1470e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.9192e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.7418e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.4985e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.3231e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 8.1298e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.9282e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.7719e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.5797e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.4148e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 7.2604e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 7.0925e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.9384e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.8080e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.6520e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 6.5065e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.3800e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.2500e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.1216e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 6.0057e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28121c460>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, vocab_size, embed_dimension, hidden_dimension, output_dimension):\n",
    "        super(CustomModel, self).__init__(name='my_model')\n",
    "        self.embedding = layers.Embedding(vocab_size, embed_dimension)\n",
    "        self.dense_layer = layers.Dense(hidden_dimension, activation='relu')\n",
    "        self.output_layer = layers.Dense(output_dimension, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.embedding(inputs)\n",
    "        x = tf.reduce_mean(x, axis=1)\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model = CustomModel(vocab_size = vocab_size,\n",
    "            embed_dimension=emb_size,\n",
    "            hidden_dimension=hidden_dimension,\n",
    "            output_dimension=output_dimension)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayer(layers.Layer):\n",
    "\n",
    "    def __init__(self, hidden_dimension, output_dimension, **kwargs):\n",
    "        self.hidden_dimension = hidden_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        super(CustomLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.dense_layer1 = layers.Dense(self.hidden_dimension, activation = 'relu')\n",
    "        self.dense_layer2 = layers.Dense(self.output_dimension)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        hidden_output = self.dense_layer1(inputs)\n",
    "        return self.dense_layer2(hidden_output)\n",
    "\n",
    "    # Optional\n",
    "    def get_config(self):\n",
    "        base_config = super(CustomLayer, self).get_config()\n",
    "        base_config['hidden_dim'] = self.hidden_dimension\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-02 14:07:40.264224: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-02 14:07:40.296582: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-02 14:07:40.328102: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-02 14:07:40.341361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 46ms/sample - loss: 0.6937 - accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.6749 - accuracy: 0.6667\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.6586 - accuracy: 0.8333\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.6427 - accuracy: 0.8333\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.6243 - accuracy: 0.8333\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.6027 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.5756 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.5489 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.5127 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.4735 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.4346 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.3889 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.3440 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.2967 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.2534 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.2126 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.1775 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.1459 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.1209 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0961 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0776 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0659 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0387 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0259 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0148 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0122 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0071 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 6ms/sample - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 7ms/sample - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 6ms/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 9.8891e-04 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 9.6363e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 9.3820e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 9.1252e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 8.9281e-04 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 8.6954e-04 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 8.4810e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 8.3099e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 8.0759e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.9138e-04 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.7264e-04 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.5325e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.3721e-04 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.2052e-04 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 7.0579e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.8895e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.7457e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.6080e-04 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.4754e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.3425e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.2002e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 6.0808e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 5ms/sample - loss: 5.9614e-04 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x173c25850>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(vocab_size, emb_size, input_length = 4),\n",
    "    layers.Lambda(lambda x: tf.reduce_mean(x, axis = 1)),\n",
    "    CustomLayer(hidden_dimension, output_dimension),\n",
    "    layers.Activation('sigmoid')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(input_sequences, labels, epochs=num_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e792887d998ce46b53b15d236ebac98e12258967697dc0a6966eabb9a0aa9c8f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
